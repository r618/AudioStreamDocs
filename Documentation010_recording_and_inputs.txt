::v3.0::1o.2o22::2019.4.0::

================================================================================
Audio input:
================================================================================

To stream audio from any available system recording input - just attach AudioSourceInput component to an empty game object and from custom script access audio buffer data of AudioSource which it automatically creates.
See how to interact with it in the AudioStreamInputDemo/AudioStreamInput2DDemo scene.
Latency is rather high for Unity spatialized input streams since it has to go via full Unity audio buffer processing. For (significantly) lower latency you can use AudioSourceInput2D component - with downside that it is 2D only.
ResonanceInput is fully spatialized and has near realtime latency (it doesn't use Unity spatialization at all)

All input components can stream/record from almost any connected input with a recording interface and they support more broader class of hardware compared to Unity Microphone class.


Currently this is best option I could come up with, for even lower latency native plugin is needed ( such as https://github.com/keijiro/Lasp ), with but the same 2D limitation since it uses just OnAudioFilterRead
[ OnAudioFilterRead has limitation of not being able to support 3D sound ]. For LASP interop with Unity AudioSource see this gist: https://gist.github.com/r618/d74f07b6049fce20f1dc0dfa546bda89 ( LASP have to be patched though currently since it can't be run not from main thread, and frequency is not exposed - those are just minor changes).
AudioSourceInput2D latency is very usable though and e.g. on iOS and recent phones it has almost immediate response to audio input in the scene.

AudioSourceInput* components will use DSP buffer setting for output #0, if specified, since FMOD's system for output #0 is also used as recording system.
See 'Devices config' in Documentation.txt



For latency you can also refer to answers to this post: http://www.fmod.org/questions/question/delaylatency-when-playing-sounds/ 

It is possible to capture and listen to the system output - for Windows, see this forum post: https://forum.unity.com/threads/audiostream-an-audio-streaming-solution-for-all-and-everywhere.412029/page-3#post-3120495
Note: don't use *loopback* interfaces for signals which should be audible/heard - this will immediately cause feedback loop -

Windows specific: any device/s which can be opened for recording, not designated as a micophone/audio input by system, is prefixed with "[loopback]" in their name by FMOD
- for example on Windows a VirtualCable port/channel can be opened and streamed into Unity this way
 -on macOS it's possible to configure new recording device using e.g. Soundflower [https://github.com/mattingalls/Soundflower], newer stuff from RogueAmoeba, or BlackHole virtual audio driver/s [https://github.com/ExistentialAudio/BlackHole]
Note that device customisation like this is only possible on desktops.

Multichannel input/microphones are supported as opposed to Unity's Microphone class.

Since the way the resampling of input signal by just setting the pitch on the AudioSource was handled led to big drifting over longer time if input and output sample rates were significantly different,
in 1.7.7 I added option to not use Unity's built AudioSource resampling and channel conversion this way.
Instead Speex resampler is used directly, with possibility to specify custom mix matrix to provide mapping between input and output channels. Default mix matrix is computed by FMOD if not customised by user.
See demo scene for reference, and call SetCustomMixMatrix on component before starting the recording, if needed.

Note that Speex resampler support for other than 1 or 2 output channels is limited and currently it works best when the rates don't differ too much - so going from lower rates usually provided by common microphones 
will probably result in not high quality audio - it might still be useful for cases where only e.g. energy of the signal is important and not the audio itself -

FMOD has limit of 'MAX_CHANNEL_WIDTH' which at the times of writing is 32 for no. of channels of its system's software format/device channels.

! For iOS/mobiles please see specific mobile recording notes.

With ResonanceInput it's possible to capture any input device and play it back in 3D - see in 3D spatialisation.


Android recording permissions:
--------------------------------------------------------------------------------
	there is a Microphone class referenced in Android specific code of AudioStreamInputBase.cs, which causes Unity to automatically include recording permission in the manifest
If you don't want/need this permission and recording in your Android build, please delete the whole 'Scripts/AudioStreamInput' folder and demos in 'Demo/AudioStreamInput' folder.


Android OpenSL ES support:
--------------------------------------------------------------------------------
	FMOD requires 'OpenSL ES' support on Android in order to enable recording - this is currently enabled for all cases/devices, even when recording is not used in the app
	- contact me if you need just playback in the app w/o recording enabled, alternatively you can just remove the requirement in FMOD_System.cs: comment out/remove 'outputType = FMOD.OUTPUTTYPE.OPENSL;'


'resampleInput' setting:
--------------------------------------------------------------------------------
	- AudioStreamInput* 's setting for better interoperability with other plugins/assets which need original sample rate of the input signal preserved (such as AVProMediaRecorder at that time) when they want to do their own resampling/encoding.
Default is ON and the input signal is resampled to current output sample rate so it can be e.g. heard normally on speakers. When OFF no resampling is done and input signal can be manually forwarded as needed - for this custom scripting is needed if it is e.g. not being captured from attached AudioSource.


'hotplugging':
--------------------------------------------------------------------------------
	Hotplugging - dynamic updates of attached input devices - can be enabled by including separate 'AudioStreamDevicesChangedNotify' component anywhere in the scene
	Devices are checked for changes in Update
	If a change is detected, an user Unity event is invoked where the new list can be queried/updated via 'AvailableInputs' again.
	'AudioStreamDevicesChangedNotify' is included in few demo scenes together with event handler.
